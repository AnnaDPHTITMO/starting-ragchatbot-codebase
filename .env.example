# Copy this file to .env and configure your LLM provider
# Format: LLM_MODEL=provider/model-name

# ============================================================
# OPTION 1: Groq (FREE - Recommended for speed)
# Sign up: https://console.groq.com
# Limits: 14,400 requests/day, ultra-fast inference
# ============================================================
# LLM_API_KEY=gsk_your_groq_api_key
# LLM_MODEL=groq/llama-3.3-70b-versatile

# ============================================================
# OPTION 2: Google Gemini (FREE - Recommended for general use)
# Sign up: https://aistudio.google.com
# Limits: 1,000 requests/day (Flash), 1M tokens/min
# ============================================================
# LLM_API_KEY=your_gemini_api_key
# LLM_MODEL=gemini/gemini-2.0-flash

# ============================================================
# OPTION 3: Mistral (FREE - High volume)
# Sign up: https://console.mistral.ai
# Limits: 1 billion tokens/month, 1 request/sec
# ============================================================
# LLM_API_KEY=your_mistral_api_key
# LLM_MODEL=mistral/mistral-small-latest

# ============================================================
# OPTION 4: OpenRouter (FREE tier available)
# Sign up: https://openrouter.ai
# Limits: 50 requests/day on free models
# ============================================================
# LLM_API_KEY=your_openrouter_api_key
# LLM_MODEL=openrouter/meta-llama/llama-3.3-70b-instruct:free

# ============================================================
# OPTION 5: Anthropic (PAID)
# Sign up: https://console.anthropic.com
# ============================================================
# LLM_API_KEY=sk-ant-your_anthropic_api_key
# LLM_MODEL=anthropic/claude-sonnet-4-20250514

# ============================================================
# OPTION 6: OpenAI (PAID)
# Sign up: https://platform.openai.com
# ============================================================
# LLM_API_KEY=sk-your_openai_api_key
# LLM_MODEL=openai/gpt-4o

# ============================================================
# OPTION 7: Ollama (FREE - Local, no API key needed)
# Install: https://ollama.ai
# Run: ollama pull llama3 && ollama serve
# ============================================================
# LLM_API_KEY=
# LLM_MODEL=ollama/llama3

# ============================================================
# ACTIVE CONFIGURATION (uncomment one option above or set here)
# ============================================================
LLM_API_KEY=your-api-key-here
LLM_MODEL=groq/llama-3.3-70b-versatile

# Legacy support: ANTHROPIC_API_KEY is also supported
# ANTHROPIC_API_KEY=your-anthropic-api-key-here
